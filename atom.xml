<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Liang&#39;s Blog</title>
  
  
  <link href="https://liang08.gitlab.io/atom.xml" rel="self"/>
  
  <link href="https://liang08.gitlab.io/"/>
  <updated>2021-01-22T03:09:55.869Z</updated>
  <id>https://liang08.gitlab.io/</id>
  
  <author>
    <name>Liang Xu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Statistical Learning Method 02</title>
    <link href="https://liang08.gitlab.io/2021/01/21/statistical-learning-method-02/"/>
    <id>https://liang08.gitlab.io/2021/01/21/statistical-learning-method-02/</id>
    <published>2021-01-21T13:18:41.000Z</published>
    <updated>2021-01-22T03:09:55.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="感知机模型">感知机模型</h1><dl><dt><strong>定义2.1（感知机）</strong></dt><dd><p>假设输入空间（特征空间）是<span class="math inline">\(\mathcal{X}\subseteq \mathbb{R}^n\)</span>，输出空间是<span class="math inline">\(y=\{+1,-1\}\)</span>。输入<span class="math inline">\(x\in\mathcal{X}\)</span>表示实例的特征向量，对应于输入空间（特征空间 ）的点；输出<span class="math inline">\(y\in\mathcal{Y}\)</span>表示实例的类别。由输入空间到输出空间的如下函数 <span class="math display">\[f(x)=\mathrm{sign}(w\cdot x + b)\]</span></p></dd><dd>称为感知机。其中，<span class="math inline">\(w\)</span>和<span class="math inline">\(b\)</span>为感知机模型参数，<span class="math inline">\(w\in\mathbb{R}^n\)</span>叫做<strong>权值（weight）</strong>，或<strong>权值向量（weight vector）</strong>，<span class="math inline">\(b\in\mathbb{R}\)</span>叫做<strong>偏置（bias）</strong>，<span class="math inline">\(w\cdot x\)</span>表示<span class="math inline">\(w\)</span>和<span class="math inline">\(x\)</span>的内积，<span class="math inline">\(\mathrm{sign}\)</span>是符号函数，即 <span class="math display">\[\mathrm{sign}(x)=\begin{cases}+1, \quad x\geqslant0\\-1, \quad x&lt;0\end{cases}\]</span></dd></dl><p>感知机是一种线性分类模型，属于<strong>判别模型</strong>，感知机模型的假设空间是定义在特征空间中的所有线性分类模型，即函数集合<span class="math inline">\(\{f|f(x) = w\cdot x + b \}\)</span></p><p>感知机有如下几何解释，线性方程 <span class="math display">\[w\cdot x + b = 0\]</span> 对应于特征空间<span class="math inline">\(\mathbb{R}^n\)</span>的一个超平面<span class="math inline">\(S\)</span>，其中<span class="math inline">\(w\)</span>是超平面的法向量，<span class="math inline">\(b\)</span>是超平面的截距。这个超平面将特征空间划分成两个部分。位于两部分的点（特征向量）分别被分为正负两类。因此，超平面<span class="math inline">\(S\)</span>称为<strong>分离超平面（Separating Hyperplane）</strong>。</p><p>感知机学习，由训练数据集（实例的特征向量即类别） <span class="math display">\[T=\{ (x_1,y_1) ,(x_2,y_2), \ldots, (x_N,y_N) \}\]</span> 求得模型参数<span class="math inline">\(w,b\)</span>。感知机预测，通过学习得到的感知机模型，对于新的输入实例给出其对应的输出类别。</p><h1 id="感知机学习策略">感知机学习策略</h1><h2 id="数据集的线性可分性">数据集的线性可分性</h2><dl><dt><strong>定义2.2（数据集的线性可分性）</strong></dt><dd><p>给定一个数据集 <span class="math display">\[T=\{ (x_1,y_1) ,(x_2,y_2), \ldots, (x_N,y_N) \}\]</span> 其中，<span class="math inline">\(x_i\in\mathcal{X} = \mathbb{R}^n,y_i\in\mathcal{Y}=\{+1, -1\},i=1,2,\ldots,N\)</span>，如果存在某个超平面 <span class="math display">\[w\cdot x + b = 0\]</span> 能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧，即对所有<span class="math inline">\(y_i=+1\)</span>的实例<span class="math inline">\(i\)</span>，有<span class="math inline">\(w\cdot x_i + b &gt; 0\)</span>，对所有<span class="math inline">\(y_i = -1\)</span>的实例<span class="math inline">\(i\)</span>，都有<span class="math inline">\(w\cdot x_i + b &lt; 0\)</span>，则数据集<span class="math inline">\(T\)</span>为<strong>线性可分数据集（Linearly Separable Dataset）</strong>；否则，称数据集<span class="math inline">\(T\)</span>线性不可分</p></dd></dl><h2 id="感知机学习策略-1">感知机学习策略</h2><p>假设训练数据集是线性可分的，感知机学习的目标是求得一个能够将训练集正实例点和负实例点完全分离的分离超平面。为此需要找到一个损失函数。</p><p>我们选择误分类点到超平面的总距离作为感知机采用的损失函数。为此，首先写出输入空间一点到超平面的距离 <span class="math display">\[\frac{1}{||w||}\left|w\cdot x_0 + b\right|\]</span> 其次对于误分类的数据<span class="math inline">\((x_i,y_i)\)</span>来说， <span class="math display">\[-y_i(w\cdot x_i + b)&gt;0\]</span> 成立。因此，误分类点<span class="math inline">\(x_i\)</span>到超平面<span class="math inline">\(S\)</span>的距离是 <span class="math display">\[-\frac{1}{||w||}y_i(w\cdot x_i + b)\]</span> 这样，假设超平面<span class="math inline">\(S\)</span>的误分类点集合为<span class="math inline">\(M\)</span>，那么所有误分类点到超平面<span class="math inline">\(S\)</span>的总距离为 <span class="math display">\[-\frac{1}{||w||}\sum_{x_i \in M}y_i(w\cdot x_i + b)\]</span> 给定训练数据集 <span class="math display">\[T=\{ (x_1,y_1) ,(x_2,y_2), \ldots, (x_N,y_N) \}\]</span></p>]]></content>
    
    
    <summary type="html">感知机</summary>
    
    
    
    <category term="Notes" scheme="https://liang08.gitlab.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/categories/Notes/Machine-Learning/"/>
    
    <category term="Statistical Learning Method" scheme="https://liang08.gitlab.io/categories/Notes/Machine-Learning/Statistical-Learning-Method/"/>
    
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/tags/Machine-Learning/"/>
    
    <category term="Artificial Intellegence" scheme="https://liang08.gitlab.io/tags/Artificial-Intellegence/"/>
    
  </entry>
  
  <entry>
    <title>Learning JavaScript 02</title>
    <link href="https://liang08.gitlab.io/2021/01/14/JavaScript-02/"/>
    <id>https://liang08.gitlab.io/2021/01/14/JavaScript-02/</id>
    <published>2021-01-14T07:43:29.000Z</published>
    <updated>2021-01-20T13:24:47.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="类型转换">类型转换</h1><p>大多数情况下，运算符和函数会自动将赋予他们的值转换为正确的类型。比如<code>alert</code>会自动将任何值都转换为字符串以进行显示。算术运算符会将值转换为数字</p><p>在某些情况下，我们需要将值显式的转换成我们期望的类型。</p><h2 id="字符串转换">字符串转换</h2><p><code>alert(value)</code>将<code>value</code>转换为字符串类型，然后显示这个值。也可以显式的调用<code>String(value)</code>来将<code>value</code>转换为字符串类型：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> value = <span class="literal">true</span>;</span><br><span class="line">alert(<span class="keyword">typeof</span> (value)) <span class="comment">//boolean</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> str = <span class="built_in">String</span>(value)</span><br><span class="line">alert(<span class="keyword">typeof</span> str)  <span class="comment">//string</span></span><br></pre></td></tr></table></figure><h2 id="数字型转换">数字型转换</h2><p>在算数函数和表达式中，会自动进行number类型转换，如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alert( <span class="string">&quot;6&quot;</span> / <span class="string">&quot;2&quot;</span> ); <span class="comment">// 3, string 类型的值被自动转换成 number 类型后进行计算</span></span><br></pre></td></tr></table></figure><p>也可以用<code>Number(value)</code>显示地将这个<code>value</code>转换为number类型。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> str = <span class="string">&quot;123&quot;</span>;</span><br><span class="line">alert(<span class="keyword">typeof</span> str); <span class="comment">// string</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> num = <span class="built_in">Number</span>(str); <span class="comment">// 变成 number 类型 123</span></span><br><span class="line"></span><br><span class="line">alert(<span class="keyword">typeof</span> num); <span class="comment">// number</span></span><br></pre></td></tr></table></figure><p>当我们从 string 类型源（如文本表单）中读取一个值，但期望输入一个数字时，通常需要进行显式转换。</p><p>如果该字符串不是一个有效的数字，转换的结果会是 <code>NaN</code>。例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> age = <span class="built_in">Number</span>(<span class="string">&quot;an arbitrary string instead of a number&quot;</span>);</span><br><span class="line"></span><br><span class="line">alert(age); <span class="comment">// NaN，转换失败</span></span><br></pre></td></tr></table></figure><p>number类型转换规则：</p><table><colgroup><col style="width: 20%" /><col style="width: 80%" /></colgroup><thead><tr class="header"><th style="text-align: left;">值</th><th style="text-align: left;">变成……</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><code>undefined</code></td><td style="text-align: left;"><code>NaN</code></td></tr><tr class="even"><td style="text-align: left;"><code>null</code></td><td style="text-align: left;"><code>0</code></td></tr><tr class="odd"><td style="text-align: left;"><code>true 和 false</code></td><td style="text-align: left;"><code>1</code> and <code>0</code></td></tr><tr class="even"><td style="text-align: left;"><code>string</code></td><td style="text-align: left;">去掉首尾空格后的纯数字字符串中含有的数字。如果剩余字符串为空，则转换结果为 <code>0</code>。否则，将会从剩余字符串中“读取”数字。当类型转换出现 error 时返回 <code>NaN</code>。</td></tr></tbody></table><h2 id="布尔类型转换">布尔类型转换</h2><p>布尔类型转换发生在逻辑运算中（稍后我们将进行条件判断和其他类似的东西），但是也可以通过调用 Boolean(value) 显式地进行转换。</p><p>转换规则如下：</p><ul><li>直观上为“空”的值（如 <code>0</code>、空字符串、<code>null</code>、<code>undefined</code> 和 <code>NaN</code>）将变为 <code>false</code>。</li><li>其他值变成 <code>true</code>。</li></ul><p>比如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alert( <span class="built_in">Boolean</span>(<span class="number">1</span>) ); <span class="comment">// true</span></span><br><span class="line">alert( <span class="built_in">Boolean</span>(<span class="number">0</span>) ); <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">alert( <span class="built_in">Boolean</span>(<span class="string">&quot;hello&quot;</span>) ); <span class="comment">// true</span></span><br><span class="line">alert( <span class="built_in">Boolean</span>(<span class="string">&quot;&quot;</span>) ); <span class="comment">// false</span></span><br></pre></td></tr></table></figure><div class="note info flat"><p>在JavaScript中，非空的字符串都是<code>true</code>，所以<code>"0"</code>也是<code>true</code></p></div><h1 id="基础运算符数学">基础运算符，数学</h1><h2 id="数学">数学</h2><p>支持以下数学运算：</p><ul><li>加法 <code>+</code>,</li><li>减法 <code>-</code>,</li><li>乘法 <code>*</code>,</li><li>除法 <code>/</code>,</li><li>取余 <code>%</code>,</li><li>求幂 <code>**</code>.</li></ul><h2 id="用二元运算符连接字符串">用二元运算符<code>+</code>连接字符串</h2><p>如果加号 <code>+</code> 被应用于字符串，它将合并（连接）各个字符串：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> s = <span class="string">&quot;my&quot;</span> + <span class="string">&quot;string&quot;</span>;</span><br><span class="line">alert(s); <span class="comment">// mystring</span></span><br></pre></td></tr></table></figure><div class="note warning flat"><p>只要任意一个运算元是字符串，那么另一个运算元也将被转化为字符串</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alert( <span class="string">&#x27;1&#x27;</span> + <span class="number">2</span> ); <span class="comment">// &quot;12&quot;</span></span><br><span class="line">alert( <span class="number">2</span> + <span class="string">&#x27;1&#x27;</span> ); <span class="comment">// &quot;21&quot;</span></span><br></pre></td></tr></table></figure><p>更复杂的例子：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alert(<span class="number">2</span> + <span class="number">2</span> + <span class="string">&#x27;1&#x27;</span> ); <span class="comment">// &quot;41&quot;，不是 &quot;221&quot;</span></span><br></pre></td></tr></table></figure><p>在这里，运算符是按顺序工作。第一个 <code>+</code> 将两个数字相加，所以返回 <code>4</code>，然后下一个 <code>+</code> 将字符串 <code>1</code> 加入其中，所以就是 <code>4 + '1' = 41</code>。</p></div><p>二元 <code>+</code> 是唯一一个以这种方式支持字符串的运算符。其他算术运算符只对数字起作用，并且总是将其运算元转换为数字。</p><h2 id="数字转化一元运算符">数字转化，一元运算符<code>+</code></h2><p>加号 <code>+</code> 应用于单个值，对数字没有任何作用。但是如果运算元不是数字，加号 <code>+</code> 则会将其转化为数字。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对数字无效</span></span><br><span class="line"><span class="keyword">let</span> x = <span class="number">1</span>;</span><br><span class="line">alert( +x ); <span class="comment">// 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> y = -<span class="number">2</span>;</span><br><span class="line">alert( +y ); <span class="comment">// -2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 转化非数字</span></span><br><span class="line">alert( +<span class="literal">true</span> ); <span class="comment">// 1</span></span><br><span class="line">alert( +<span class="string">&quot;&quot;</span> );   <span class="comment">// 0</span></span><br></pre></td></tr></table></figure><p>效果和<code>Number()</code>相同</p><h2 id="运算符优先级">运算符优先级</h2><p>完整的<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_Precedence">优先级表</a>可以从这里看到。一元运算符的优先级高于二元运算符</p><h2 id="位运算符">位运算符</h2><p>位运算符把运算元当做 32 位整数，并在它们的二进制表现形式上操作。</p><p>这些运算符不是 JavaScript 特有的。大部分的编程语言都支持这些运算符。</p><p>下面是位运算符：</p><ul><li>按位与 ( <code>&amp;</code> )</li><li>按位或 ( <code>|</code> )</li><li>按位异或 ( <code>^</code> )</li><li>按位非 ( <code>~</code> )</li><li>左移 ( <code>&lt;&lt;</code> )</li><li>右移 ( <code>&gt;&gt;</code> )</li><li>无符号右移 ( <code>&gt;&gt;&gt;</code> )</li></ul><h2 id="逗号运算符">逗号运算符</h2><p>逗号运算符能让我们处理多个语句，使用 <code>,</code> 将它们分开。每个语句都运行了，但是只有最后的语句的结果会被返回。例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> a = (<span class="number">1</span> + <span class="number">2</span>, <span class="number">3</span> + <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">alert( a ); <span class="comment">// 7（3 + 4 的结果）</span></span><br></pre></td></tr></table></figure><h1 id="值的比较">值的比较</h1><h2 id="字符串的比较">字符串的比较</h2><p>在比较字符串的大小时，JavaScript 会使用“字典（dictionary）”或“词典（lexicographical）”顺序进行判定。</p><ol type="1"><li>首先比较两个字符串的首位字符大小。</li><li>如果一方字符较大（或较小），则该字符串大于（或小于）另一个字符串。算法结束。</li><li>否则，如果两个字符串的首位字符相等，则继续取出两个字符串各自的后一位字符进行比较。</li><li>重复上述步骤进行比较，直到比较完成某字符串的所有字符为止。</li><li>如果两个字符串的字符同时用完，那么则判定它们相等，否则未结束（还有未比较的字符）的字符串更大。</li></ol><h2 id="不同类型之间的比较">不同类型之间的比较</h2><p>当对不同类型的值进行比较时，JavaScript 会首先将其转化为数字（number）再判定大小，例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alert( <span class="string">&#x27;2&#x27;</span> &gt; <span class="number">1</span> ); <span class="comment">// true，字符串 &#x27;2&#x27; 会被转化为数字 2</span></span><br><span class="line">alert( <span class="string">&#x27;01&#x27;</span> == <span class="number">1</span> ); <span class="comment">// true，字符串 &#x27;01&#x27; 会被转化为数字 1</span></span><br></pre></td></tr></table></figure><p>对于布尔类型值，<code>true</code> 会被转化为 <code>1</code>、<code>false</code> 转化为 <code>0</code>，例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alert( <span class="literal">true</span> == <span class="number">1</span> ); <span class="comment">// true</span></span><br><span class="line">alert( <span class="literal">false</span> == <span class="number">0</span> ); <span class="comment">// true</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">JavaScript基础知识 02</summary>
    
    
    
    <category term="Programming Languages" scheme="https://liang08.gitlab.io/categories/Programming-Languages/"/>
    
    <category term="JavaScript" scheme="https://liang08.gitlab.io/categories/Programming-Languages/JavaScript/"/>
    
    
    <category term="JavaScript" scheme="https://liang08.gitlab.io/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 02 —— Autoguard</title>
    <link href="https://liang08.gitlab.io/2021/01/13/Pytorch-02/"/>
    <id>https://liang08.gitlab.io/2021/01/13/Pytorch-02/</id>
    <published>2021-01-13T01:14:47.000Z</published>
    <updated>2021-01-21T13:17:50.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="张量tensor">张量(Tensor)</h1><p><code>torch.Tensor</code>是包的核心类。如果将属性<code>.requires_grad</code>设置为<code>True</code>，则会开始跟踪上面的所有操作。完成计算后，可以调用<code>.backward()</code>并自动计算所有梯度。张量的梯度将累积到<code>.grad</code>属性中</p><p>要阻止张量跟踪历史记录，可以调用<code>.detach()</code>将其从计算历史中分离出来，并防止将来的计算被跟踪</p><p>要防止跟踪历史记录（和使用内存），还可以使用<code>torch.no_grad()</code>包中那个代码块</p><p>还有一个类对于autograd实现非常重要 - Function。</p><p>Tensor和Function互相连接并构建一个非循环图构建一个完整的计算过程。每个张量都有一个<code>.grad_fn</code>属性，该属性引用已创建Tensor的Function（除了用户创建的Tensors - 它们的<code>grad_fn</code>为<code>None</code>）。</p><p>如果要计算导数，可以在Tensor上调用<code>.backward()</code>。如果Tensor是标量（即它包含一个元素数据），则不需要为<code>backward()</code>指定任何参数，但是如果它有更多元素，则需要指定一个梯度参数，该参数是匹配形状的张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个张量并设置 requires_grad = True 以跟踪它的计算</span></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">tensor([[1., 1.],</span></span><br><span class="line"><span class="string">        [1., 1.]], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>在张量上执行操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y = x + <span class="number">2</span></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">tensor([[3., 3.],</span></span><br><span class="line"><span class="string">        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>因为y是通过一个操作创建的，所以它有<code>grad_fn</code>，而x是用户创建的，所以它的<code>grad_fn</code>为<code>None</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(y.grad_fn)</span><br><span class="line">print(x.grad_fn)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">&lt;AddBackward0 object at 0x7f854061ec50&gt;</span></span><br><span class="line"><span class="string">None</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>在y上执行操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">z = y * y * <span class="number">3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z, out)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">tensor([[27., 27.],</span></span><br><span class="line"><span class="string">        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>.requires\_grad_(...)</code>就地更改现有的Tensor的<code>requires_grad</code>标志。 如果没有给出，输入标志默认为False。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line">print(a.requires_grad)</span><br><span class="line"></span><br><span class="line">a.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">print(a.requires_grad)</span><br><span class="line"></span><br><span class="line">b = (a * a).<span class="built_in">sum</span>()</span><br><span class="line">print(b.grad_fn)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">&lt;SumBackward0 object at 0x7f8540621090&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="梯度">梯度</h1><p>来执行反向传播,<code>out.backward()</code>，相当于执行<code>out.backward(torch.tensor(1.))</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out.backward()</span><br></pre></td></tr></table></figure><p>输出out对x的梯度<span class="math inline">\(\frac{\mathrm{d}(out)}{\mathrm{d}x}\)</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[4.5000, 4.5000],</span></span><br><span class="line"><span class="string">        [4.5000, 4.5000]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>得到一个值全为4.5的矩阵，我们把张量out称为"<span class="math inline">\(o\)</span>"，则 <span class="math display">\[o=\frac{1}{4}\sum_{i}z_i, \quad z_i=3(x_i+2)^2\]</span> 并且<span class="math inline">\(z\left|_{x_i=1}=27 \right.\)</span>，所以，<span class="math inline">\(\frac{\partial o}{\partial x_i}=\frac{3}{2}(x_i+2)\)</span>，因此，<span class="math inline">\(\frac{\partial o}{\partial x_i}\left|_{x_i=1} \right.=\frac{9}{2}=4.5\)</span>，在数学上，如果有一个向量值函数<span class="math inline">\(\vec{y}=f(\vec{x})\)</span>，则<span class="math inline">\(\vec{y}\)</span>相对于<span class="math inline">\(\vec{x}\)</span>的梯度是雅可比矩阵： <span class="math display">\[J=\begin{pmatrix}\frac{\partial y_1}{\partial x_1} &amp; \ldots &amp; \frac{\partial y_m}{\partial x_1}\\\vdots &amp; \ddots &amp; \vdots\\\frac{\partial y_1}{\partial x_n} &amp; \ldots &amp; \frac{\partial y_m}{\partial x_n}\end{pmatrix}\]</span> 一般来说，<code>touch.autograd</code>是一个计算雅克比向量积的引擎。也就是说，给定任何向量<span class="math inline">\(v=(v_1,v_2,\ldots,v_m)^T\)</span>，计算乘积<span class="math inline">\(J\cdot v\)</span>。如果<span class="math inline">\(v\)</span>恰好是标量函数的梯度<span class="math inline">\(l=g(\vec{y})\)</span>，即<span class="math inline">\(v=(\frac{\partial l}{\partial y_1},\frac{\partial l}{\partial y_2},\ldots,\frac{\partial l}{\partial y_m})\)</span>，然后根据链式法则，雅克比向量乘积将是<span class="math inline">\(l\)</span>相对于<span class="math inline">\(\vec{x}\)</span>的梯度 <span class="math display">\[J\cdot v=\begin{pmatrix}\frac{\partial y_1}{\partial x_1} &amp; \ldots &amp; \frac{\partial y_m}{\partial x_1}\\\vdots &amp; \ddots &amp; \vdots\\\frac{\partial y_1}{\partial x_n} &amp; \ldots &amp; \frac{\partial y_m}{\partial x_n}\end{pmatrix}\begin{pmatrix}\frac{\partial l}{\partial y_1}\\\vdots\\\frac{\partial l}{\partial y_n}\end{pmatrix}=\begin{pmatrix}\frac{\partial l}{\partial x_1}\\\vdots\\\frac{\partial l}{\partial x_n}\end{pmatrix}\]</span> 雅可比向量积的这种特性使得将外部梯度馈送到具有非标量输出的模型中非常方便。</p><p>现在来看一个雅可比向量积的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x * <span class="number">2</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">tensor([  863.9843, -1275.6700,    29.5176], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>现在在这种情况下，y不再是标量。 <code>torch.autograd</code>无法直接计算完整雅可比行列式，但如果我们只想要雅可比向量积，只需将向量作为参数向后传递：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v)</span><br><span class="line">print(x.grad)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>还可以通过<code>torch.no_grad()</code>代码，在张量上使用<code>.requires_grad = True</code>来停止使用跟踪历史记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line">    </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">True</span></span><br><span class="line"><span class="string">False</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>关于<code>autograd</code>和<code>Function</code>的文档见<a href="https://pytorch.org/docs/stable/autograd.html">此文档</a></p>]]></content>
    
    
    <summary type="html">autograd包为张量上的所有操作提供了自动求导.它是一个运行时定义的框架,这意味着反向传播是根据你的代码如何运行来定义,并且每次迭代可以不同.</summary>
    
    
    
    <category term="Programming Languages" scheme="https://liang08.gitlab.io/categories/Programming-Languages/"/>
    
    <category term="Python" scheme="https://liang08.gitlab.io/categories/Programming-Languages/Python/"/>
    
    <category term="Pytorch" scheme="https://liang08.gitlab.io/categories/Programming-Languages/Python/Pytorch/"/>
    
    
    <category term="Python" scheme="https://liang08.gitlab.io/tags/Python/"/>
    
    <category term="Pytorch" scheme="https://liang08.gitlab.io/tags/Pytorch/"/>
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Learning JavaScript 01</title>
    <link href="https://liang08.gitlab.io/2021/01/10/JavaScript-01/"/>
    <id>https://liang08.gitlab.io/2021/01/10/JavaScript-01/</id>
    <published>2021-01-10T14:04:12.000Z</published>
    <updated>2021-01-14T07:43:01.295Z</updated>
    
    <content type="html"><![CDATA[<h1 id="html中的javascript">HTML中的JavaScript</h1><h2 id="script标签">“script”标签</h2><p>JavaScript程序可以在<code>&lt;script&gt;</code>标签的帮助下插入到HTML文档的任何地方，比如：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">HTML</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>script 标签之前...<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">    alert(<span class="string">&#x27;Hello, world!&#x27;</span>);</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">p</span>&gt;</span>...script 标签之后<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>&lt;script&gt;</code>标签中包裹了JavaScript代码，当浏览器遇到<code>&lt;script&gt;</code></p><h2 id="外部脚本">外部脚本</h2><p>如果含有大量JavaScript代码，可以将其放入一个单独的文件中，脚本可以通过<code>src</code>特性（attribute）添加到HTML文件中</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;/path/to/script.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这里，<code>/path/to/script.js</code>是脚本文件从网站根目录开始绝对路径，也可以提供相对路径或完整的URL地址。</p><p>要附加多个脚本，需要使用多个标签</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src-</span>&quot;/<span class="attr">js</span>/<span class="attr">script1.js</span>&quot;&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src-</span>&quot;/<span class="attr">js</span>/<span class="attr">script2.js</span>&quot;&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><div class="note warning flat"><p>如果设置了<code>src</code>特性，<code>script</code>标签内容将被忽略</p></div><h1 id="代码结构">代码结构</h1><h2 id="分号">分号</h2><p>当存在换行符（line break）时，在大多数情况下可以省略分号，如</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alert(<span class="string">&#x27;Hello&#x27;</span>)</span><br><span class="line">alert(<span class="string">&#x27;World&#x27;</span>)</span><br></pre></td></tr></table></figure><p>此时，JavaScript将换行理解成“隐式”的分号，这被称为<strong>自动分号插入</strong>，但是并不总是这样的，例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alert(<span class="number">3</span> +</span><br><span class="line"><span class="number">1</span></span><br><span class="line">+ <span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>会输出<code>6</code>，因为JavaScript没有在这里加入分号。</p><div class="note info simple"><p>即使大部分时候可以省略分号，但最好还是不要省略</p></div><h2 id="注释">注释</h2><p>单行注释以两个正斜杠<code>//</code>开始，剩余部分是注释，如</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这行注释独占一行</span></span><br><span class="line">alert(<span class="string">&#x27;Hello&#x27;</span>);</span><br><span class="line"></span><br><span class="line">alert(<span class="string">&#x27;World&#x27;</span>); <span class="comment">// 这行注释跟随在语句后面</span></span><br></pre></td></tr></table></figure><p>多行注释以<code>/*</code>开始，以<code>*/</code>结束，如</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 两个消息的例子。</span></span><br><span class="line"><span class="comment">这是一个多行注释</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">alert(<span class="string">&#x27;World&#x27;</span>);</span><br></pre></td></tr></table></figure><div class="note warning flat"><p>不支持注释嵌套</p><p>不能再<code>/**/</code>中嵌套一个<code>/**/</code></p></div><h1 id="变量">变量</h1><h2 id="变量-1">变量</h2><p>在JavaScript中创建一个变量，我们需要用到<code>let</code>关键字</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> message;</span><br></pre></td></tr></table></figure><p>创建了一个名为“message”的变量。</p><h3 id="变量命名">变量命名</h3><p>JavaScript的变量命名有两个限制：</p><ol type="1"><li>变量名必须仅包含字母，数字，符号<code>$</code>和<code>_</code></li><li>首字母必须非数字</li></ol><p>如果命名包括多个单词，通常采用驼峰式命名法，也就是，单词一个接一个，除了第一个单词，其他的每个单词都以大写字母开头：<code>myVeryLongName</code>。</p><div class="note info flat"><p>区分大小写，允许非英文字母</p></div><div class="note warning flat"><p>有一张<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Lexical_grammar#keywords">保留字列表</a>，表中的保留字无法作为变量名</p></div><h2 id="常量">常量</h2><p>声明一个常数变量，可以使用<code>const</code>而非<code>let</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> myBirthday = <span class="string">&#x27;01.01.2001&#x27;</span></span><br></pre></td></tr></table></figure><p>使用<code>const</code>声明的变量称为“常量”。它们不能被修改，如果尝试修改就会报错</p><p>当能确定一个量不会改变是，就将其声明为常量，来传递这个信息</p><h1 id="数据类型">数据类型</h1><p>JavaScript中的值都有特定的类型，在JavaScript中有8种基本的数据类型。我们可以将任何类型的值存入变量，如</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> message = <span class="string">&#x27;Hello&#x27;</span>;</span><br><span class="line">message = <span class="number">123</span>;</span><br></pre></td></tr></table></figure><p>允许这种操作的编程语言，被称为<strong>动态类型</strong>的编程语言</p><h2 id="number类型">Number类型</h2><p><em>number</em>类型代表整数和浮点数。数字可以有很多种操作，比如，乘法 <code>*</code>、除法 <code>/</code>、加法 <code>+</code>、减法 <code>-</code></p><p>除了常规的数字，还包括“特殊数值”（“special numeric values”）：<code>Infinity</code>，<code>-Infinity</code>，<code>NaN</code>。</p><ul><li><p><code>Infinity</code>代表数学中的无穷大<span class="math inline">\(\infty\)</span>，可以通过除以<span class="math inline">\(0\)</span>或直接使用来得到它</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alert(<span class="number">1</span> / <span class="number">0</span>); <span class="comment">//Infinity</span></span><br><span class="line">alert(<span class="literal">Infinity</span>); <span class="comment">//Infinity</span></span><br></pre></td></tr></table></figure></li><li><p><code>NaN</code>代表一个计算错误。它是一个不正确或者未定义的一个数学操作所得到的结果，比如</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alert(<span class="string">&quot;not a number&quot;</span> / <span class="number">2</span>); <span class="comment">//这样的除法是错误的</span></span><br></pre></td></tr></table></figure><p><code>NaN</code>是粘性的。对任何<code>NaN</code>的进一步操作都会返回<code>NaN</code></p></li></ul><div class="note info flat"><p>在JavaScript中做数学运算是安全的，最坏情况会返回<code>NaN</code></p></div><h2 id="bigint类型">BigInt类型</h2><p>在JavaScript中，“number”类型无法表示大于<code>2^53 - 1</code>的整数，要表示超过这个范围的数字时，需要用到<em>BigInt</em>类型。<em>BigInt</em>可以表示任意长度的整数。可以通过将<code>n</code>附加到整数字段的末尾来创建<code>BigInt</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> bigInt = <span class="number">1234567890123456789012345678901234567890n</span>;</span><br></pre></td></tr></table></figure><h2 id="string类型">String类型</h2><p>JavaScript中的字符串必须被括在引号里</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> str = <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line"><span class="keyword">let</span> str2 = <span class="string">&#x27;Single quotes&#x27;</span>;</span><br><span class="line"><span class="keyword">let</span> phrase = <span class="string">`can embed another <span class="subst">$&#123;str&#125;</span>`</span>;</span><br></pre></td></tr></table></figure><p>在JavaScript中，有三种包含字符串的方法</p><ol type="1"><li>双引号：<code>"Hello"</code></li><li>单引号：<code>'Hello'</code></li><li>反引号</li></ol><p>双引号和单引号都是“简单”引用,反引号是 <strong>功能扩展</strong> 引号。它们允许我们通过将变量和表达式包装在 <code>$&#123;…&#125;</code> 中，来将它们嵌入到字符串中。例如：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> name = <span class="string">&quot;John&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 嵌入一个变量</span></span><br><span class="line">alert( <span class="string">`Hello, <span class="subst">$&#123;name&#125;</span>!`</span> ); <span class="comment">// Hello, John!</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 嵌入一个表达式</span></span><br><span class="line">alert( <span class="string">`the result is <span class="subst">$&#123;<span class="number">1</span> + <span class="number">2</span>&#125;</span>`</span> ); <span class="comment">// the result is 3</span></span><br></pre></td></tr></table></figure><p><code>$&#123;…&#125;</code> 内的表达式会被计算，计算结果会成为字符串的一部分。可以在 <code>$&#123;…&#125;</code> 内放置任何东西：诸如名为 <code>name</code> 的变量，或者诸如 <code>1 + 2</code> 的算数表达式，或者其他一些更复杂的。</p><h2 id="boolean类型逻辑类型">Boolean类型（逻辑类型）</h2><p>boolean类型仅包含两个值：<code>true</code>和<code>false</code></p><h2 id="null值">”null“值</h2><p>特殊的<code>null</code>值不属于上述任何一种类型，它构成了一个独立的类型，只包含<code>null</code>值</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> age = <span class="literal">null</span>;</span><br></pre></td></tr></table></figure><h2 id="undefined值">”undefined“值</h2><p>特殊值<code>undefined</code>和<code>null</code>一样自成类型。<code>undefined</code>的含义是<strong>未被赋值</strong>，如果一个变量已经被定义，但是未被赋值，那么它的值就是<code>undefined</code>：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> age;</span><br><span class="line">alert(age); <span class="comment">//弹出”undefined“</span></span><br></pre></td></tr></table></figure><h2 id="object类型和symbol类型">object类型和symbol类型</h2><p><code>object</code>类型是一个特殊的类型，用于储存数据几何体和更复杂的实体。<code>symbol</code>类型用于创建对象的唯一标识符。</p><h2 id="typeof运算符">typeof运算符</h2><p><code>typeof</code> 运算符返回参数的类型。当我们想要分别处理不同类型值的时候，或者想快速进行数据类型检验时，非常有用。</p><p>它支持两种语法形式：</p><ol type="1"><li>作为运算符：<code>typeof x</code>。</li><li>函数形式：<code>typeof(x)</code>。</li></ol><p>换言之，有括号和没有括号，得到的结果是一样的。</p><p>对 <code>typeof x</code> 的调用会以字符串的形式返回数据类型：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typeof</span> <span class="literal">undefined</span> <span class="comment">// &quot;undefined&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="number">0</span> <span class="comment">// &quot;number&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="number">10n</span> <span class="comment">// &quot;bigint&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="literal">true</span> <span class="comment">// &quot;boolean&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="string">&quot;foo&quot;</span> <span class="comment">// &quot;string&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="built_in">Symbol</span>(<span class="string">&quot;id&quot;</span>) <span class="comment">// &quot;symbol&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="built_in">Math</span> <span class="comment">// &quot;object&quot;  (1)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> <span class="literal">null</span> <span class="comment">// &quot;object&quot;  (2)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typeof</span> alert <span class="comment">// &quot;function&quot;  (3)</span></span><br></pre></td></tr></table></figure><h1 id="交互alertprompt和confirm">交互：alert、prompt和confirm</h1><h2 id="alert">alert</h2><p>会显示一条信息，并等待用户按下”OK“。</p><p>弹出的这个带有信息的小窗口被称为 <strong>模态窗</strong>。“modal” 意味着用户不能与页面的其他部分（例如点击其他按钮等）进行交互，直到他们处理完窗口。在上面示例这种情况下 —— 直到用户点击“确定”按钮。</p><h2 id="prompt">prompt</h2><p><code>prompt</code>函数接收两个参数：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = prompt(title, [<span class="keyword">default</span>]);</span><br></pre></td></tr></table></figure><p>浏览器会显示一个带有文本消息的模态窗口，还有 input 框和确定/取消按钮。</p><ul><li><p><code>title</code></p><p>显示给用户的文本</p></li><li><p><code>default</code></p><p>可选的第二个参数，指定 input 框的初始值。</p></li></ul><p>访问者可以在提示输入栏中输入一些内容，然后按“确定”键。然后我们在 <code>result</code> 中获取该文本。或者他们可以按取消键或按 Esc 键取消输入，然后我们得到 <code>null</code> 作为 <code>result</code>。</p><p><code>prompt</code> 将返回用户在 <code>input</code> 框内输入的文本，如果用户取消了输入，则返回 <code>null</code>。</p><h2 id="confirm">confirm</h2><p>语法：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = confirm(question);</span><br></pre></td></tr></table></figure><p><code>confirm</code> 函数显示一个带有 <code>question</code> 以及确定和取消两个按钮的模态窗口。</p><p>点击确定返回 <code>true</code>，点击取消返回 <code>false</code>。</p>]]></content>
    
    
    <summary type="html">JavaScript基础知识 01</summary>
    
    
    
    <category term="Programming Languages" scheme="https://liang08.gitlab.io/categories/Programming-Languages/"/>
    
    <category term="JavaScript" scheme="https://liang08.gitlab.io/categories/Programming-Languages/JavaScript/"/>
    
    
    <category term="JavaScript" scheme="https://liang08.gitlab.io/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch 01 —— Tensors</title>
    <link href="https://liang08.gitlab.io/2021/01/10/Pytorch-01/"/>
    <id>https://liang08.gitlab.io/2021/01/10/Pytorch-01/</id>
    <published>2021-01-10T10:27:39.000Z</published>
    <updated>2021-01-12T02:15:52.797Z</updated>
    
    <content type="html"><![CDATA[<h1 id="tensors张量">Tensors(张量)</h1><p>Tensor是一种特殊的数据结构，它与array和matrix类似。在Pytorch中，我们用tensor来储存一个模型的输入和输出。Tensor与numpy中的ndarrays类似，但是tensor能使用GPU等硬件设备来加速计算。在使用之前要引入以下库：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h1 id="tensor初始化">Tensor初始化</h1><p>tensor有多种初始化的方法：</p><h2 id="从基本数据类型出发">从基本数据类型出发</h2><p>tensor可由基本数据类型初始化，tensor的数据类型可以自动推导</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">x_data = torch.tensor(data)</span><br></pre></td></tr></table></figure><h2 id="从numpy-array出发">从Numpy array出发</h2><p>Tensor可以由Numpy array 类型初始化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">np_array = np.array(data)</span><br><span class="line">x_np = torch.from_numpy(np_array)</span><br></pre></td></tr></table></figure><h2 id="从另一个tensor出发">从另一个Tensor出发</h2><p>Tensor可以由另一个tensor构建，它保持了原Tensor的性质（shape,dtype），除非提供新值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_ones = torch.ones_like(x_data)</span><br><span class="line">print(<span class="string">f&quot;Ones Tensor: \n <span class="subst">&#123;x_ones&#125;</span> \n&quot;</span>)</span><br><span class="line">x_rand = torch.rand_like(x_data, dtype = torch.<span class="built_in">float</span>)</span><br><span class="line">print(<span class="string">f&quot;Random Tensor: \n <span class="subst">&#123;x_rand&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Ones Tensor: </span><br><span class="line"> tensor([[1, 1],</span><br><span class="line">        [1, 1]]) </span><br><span class="line"></span><br><span class="line">Random Tensor: </span><br><span class="line"> tensor([[0.4990, 0.6255],</span><br><span class="line">        [0.4148, 0.0162]]) </span><br></pre></td></tr></table></figure><h2 id="随机数或常数">随机数或常数</h2><p>有几个用来构建Tensor的常用函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">shape = (<span class="number">2</span>, <span class="number">3</span>)  <span class="comment">#shape是一个用来表示tensor各维数量的tuple</span></span><br><span class="line">rand_tensor = torch.rand(shape)</span><br><span class="line">ones_tensor = torch.ones(shape)</span><br><span class="line">zeros_tensor = torch.zeros(shape)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&quot;Random Tensor: \n <span class="subst">&#123;rand_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Ones Tensor: \n <span class="subst">&#123;ones_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Zeros Tensor: \n <span class="subst">&#123;zeros_tensor&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Random Tensor: </span><br><span class="line"> tensor([[0.2932, 0.9156, 0.9483],</span><br><span class="line">        [0.4570, 0.9828, 0.2313]]) </span><br><span class="line"></span><br><span class="line">Ones Tensor: </span><br><span class="line"> tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]]) </span><br><span class="line"></span><br><span class="line">Zeros Tensor: </span><br><span class="line"> tensor([[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]])</span><br></pre></td></tr></table></figure><h1 id="tensor属性">Tensor属性</h1><p>一个Tensor有多个属性，它们描述了tensor的shape, dtype和储存设备（CPU, GPU等）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;tensor.dtype&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;tensor.device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Shape of tensor: torch.Size([3, 4])</span><br><span class="line">Datatype of tensor: torch.float32</span><br><span class="line">Device tensor is stored on: cpu</span><br></pre></td></tr></table></figure><h1 id="tensor操作">Tensor操作</h1><p>Tensor可以执行多种命令，具体的命令列表<a href="https://pytorch.org/docs/stable/torch.html">见此网页</a>，下面列举一些常用的</p><h2 id="转移到gpu">转移到GPU</h2><p>如果有GPU和cuda，可以将tensor转移到GPU上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">  tensot = tensor.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="索引和切片">索引和切片</h2><p>Tensor具有和numpy类似的索引和切片方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.ones(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">tensor[:, <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">print(tensor)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure><h2 id="tensor合并">Tensor合并</h2><p>可以使用<code>torch.cat</code>函数来合并几个tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1 = t1 = torch.cat([tensor, tensor, tensor], dim = <span class="number">1</span>)</span><br><span class="line">print(t1)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure><h2 id="tensor乘法">Tensor乘法</h2><p>Tensor的乘法主要有两种，一种是Tensor中<strong>各元素直接相乘</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This computes the element-wise product</span></span><br><span class="line">print(<span class="string">f&quot;tensor.mul(tensor) \n <span class="subst">&#123;tensor.mul(tensor)&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="comment"># Alternative syntax:</span></span><br><span class="line">print(<span class="string">f&quot;tensor * tensor \n <span class="subst">&#123;tensor * tensor&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor.mul(tensor) </span><br><span class="line"> tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]]) </span><br><span class="line"></span><br><span class="line">tensor * tensor </span><br><span class="line"> tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure><p>另一种是Tensor的<strong>矩阵相乘</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">f&quot;tensor.matmul(tensor.T) \n <span class="subst">&#123;tensor.matmul(tensor.T)&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="comment"># Alternative syntax:</span></span><br><span class="line">print(<span class="string">f&quot;tensor @ tensor.T \n <span class="subst">&#123;tensor @ tensor.T&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor.matmul(tensor.T) </span><br><span class="line"> tensor([[3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.]]) </span><br><span class="line"></span><br><span class="line">tensor @ tensor.T </span><br><span class="line"> tensor([[3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.]])</span><br></pre></td></tr></table></figure><h2 id="原地操作">原地操作</h2><p>带有<code>_</code>后缀的操作是原地操作。比如<code>x = copy_(y)</code>，<code>x = t_()</code>会改变x的值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(tensor, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">tensor.add_(<span class="number">2</span>)</span><br><span class="line">print(tensor)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]]) </span><br><span class="line"></span><br><span class="line">tensor([[3., 2., 3., 3.],</span><br><span class="line">        [3., 2., 3., 3.],</span><br><span class="line">        [3., 2., 3., 3.],</span><br><span class="line">        [3., 2., 3., 3.]])</span><br></pre></td></tr></table></figure><h1 id="numpy-和-tensor-的联系">Numpy 和 Tensor 的联系</h1><p>在CPU上的Tensor和Numpy array共享一块内存空间，因此改变一个会带来另一个的改变</p><h2 id="tensor到numpy-array">Tensor到Numpy array</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(<span class="string">f&quot;t: <span class="subst">&#123;t&#125;</span>&quot;</span>)</span><br><span class="line">n = t.numpy()</span><br><span class="line">print(<span class="string">f&quot;n: <span class="subst">&#123;n&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t: tensor([1., 1., 1., 1., 1.])</span><br><span class="line">n: [1. 1. 1. 1. 1.]</span><br></pre></td></tr></table></figure><h2 id="numpy-array到tensor">Numpy array到Tensor</h2><p>调用<code>from_numpy</code>函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n = np.ones(<span class="number">5</span>)</span><br><span class="line">t = torch.from_numpy(n)</span><br></pre></td></tr></table></figure><h2 id="两者的关联">两者的关联</h2><p>改变Tensor或Numpy array中的任一个都会使得另一个发生改变</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">np.add(n, <span class="number">1</span>, out=n)</span><br><span class="line">print(<span class="string">f&quot;t: <span class="subst">&#123;t&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;n: <span class="subst">&#123;n&#125;</span>&quot;</span>)</span><br><span class="line">t.add_(<span class="number">1</span>)</span><br><span class="line">print(<span class="string">f&quot;t: <span class="subst">&#123;t&#125;</span>&quot;</span>)</span><br><span class="line">print(<span class="string">f&quot;n: <span class="subst">&#123;n&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t: tensor([2., 2., 2., 2., 2.])</span><br><span class="line">n: [2. 2. 2. 2. 2.]</span><br><span class="line">t: tensor([3., 3., 3., 3., 3.])</span><br><span class="line">n: [3. 3. 3. 3. 3.]</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Tensor，中文叫张量，本质是一个多维数组，目的是能创造更高维度的矩阵、向量</summary>
    
    
    
    <category term="Programming Languages" scheme="https://liang08.gitlab.io/categories/Programming-Languages/"/>
    
    <category term="Python" scheme="https://liang08.gitlab.io/categories/Programming-Languages/Python/"/>
    
    <category term="Pytorch" scheme="https://liang08.gitlab.io/categories/Programming-Languages/Python/Pytorch/"/>
    
    
    <category term="Python" scheme="https://liang08.gitlab.io/tags/Python/"/>
    
    <category term="Pytorch" scheme="https://liang08.gitlab.io/tags/Pytorch/"/>
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Statistical Learning Method 01</title>
    <link href="https://liang08.gitlab.io/2020/12/27/statistical-learning-method-1/"/>
    <id>https://liang08.gitlab.io/2020/12/27/statistical-learning-method-1/</id>
    <published>2020-12-27T01:14:47.000Z</published>
    <updated>2021-01-18T12:34:19.575Z</updated>
    
    <content type="html"><![CDATA[<h1 id="统计学习">统计学习</h1><p>统计学习(Statistical Learning)是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习(Statistical Machine Learning)。</p><h1 id="基本分类">基本分类</h1><h2 id="监督学习supervised-learning">监督学习(Supervised Learning)</h2><h3 id="输入空间特征空间与输出空间">输入空间、特征空间与输出空间</h3><p>在监督学习中，将输入与输出所有可能性的集合分别称为<strong>输入空间(Input Space) 与输出空间(Output Space)</strong>。输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。</p><p>每个具体的输入时一个<strong>实例(Instance)</strong>，通常由<strong>特征向量(Feature Vector)</strong>表示。所有特征向量存在的空间称为<strong>特种空间(Feature Space)</strong>。特征空间的每一维对应一个特征。</p><p>在监督学习中，将输入与输出看做是定义在输入（特征）空间上的与输出空间上的随机变量的取值。输入输出变量用大写字母表示，变量的取值用小写字母表示。输入实例<span class="math inline">\(x\)</span>的特征向量记作 <span class="math display">\[x = \left( x^{(1)}, x^{(2)}, \ldots , x^{(i)}, \ldots, x^{(n)} \right)^T\]</span> 监督学习从训练数据（training data）集合中学习模型，对测试数据（test data）进行预测。训练数据由输入（或特征向量）与输出对组成，训练集通常表示为 <span class="math display">\[T=\left\{ (x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n) \right\}\]</span> 测试数据也由输入与输出对组成。输入与输出对又称为样本（sample）或样本点</p><p>输入变量<span class="math inline">\(X\)</span>和输出变量<span class="math inline">\(Y\)</span>有不同的类型，可以是连续的，也可以使离散的。根据输入输出变量的不同类型，对预测人物给予不同的名称：输入变量与输出变量均为连续变量的预测问题称为<strong>回归问题</strong>，输出变量为有限个离散变量的预测问题为<strong>分类问题</strong>；输入变量和输出变量均为变量序列的预测问题为<strong>标注问题</strong></p><h3 id="联合概率分布">联合概率分布</h3><p>监督学习假设输入和输出的随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>遵循联合概率分布<span class="math inline">\(P(X,Y)\)</span>。在学习的过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据和册数数据被看做是依照联合概率分布<span class="math inline">\(P(X,Y)\)</span>独立同分布产生的</p><h3 id="假设空间">假设空间</h3><p>监督学习的目的在于学习一个由输入到输出的映射。这个映射由模型来表示，学习的摸底是找到最好的模型。模型属于由输入空间到输出空间的映射的集合，这个集合就是<strong>假设空间（hypothesis space）</strong>。假设空间的确定意味着学习范围的确定。</p><p>监督学习的模型可以是概率模型或非概率模型。由条件概率分布<span class="math inline">\(P(Y|X)\)</span>或决策函数（decision function）<span class="math inline">\(Y=f(X)\)</span>表示</p><h3 id="问题的形式化">问题的形式化</h3><p>减速学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。监督学习分为<strong>学习</strong>和<strong>预测</strong>两个构成，由<strong>学习系统和预测系统</strong>完成</p><div class="mermaid">graph LRA[学习系统] --&gt;B[(模型)]  B --&gt; C[预测系统]  C --&gt; B D[测试样本X] --&gt; C  C --&gt; E[测试样本Y]</div><p>首先给定一个训练数据集 <span class="math display">\[T=\left\{ (x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N) \right\}\]</span> 其中<span class="math inline">\((x_i, y_i),i=1,2,\ldots,n\)</span>称为样本或样本点。<span class="math inline">\(x_i\in \mathcal{X}\subseteq \mathbb{R}^n\)</span>是输入的观测值，也称为输入或实例，<span class="math inline">\(y_i\in\mathcal{Y}\)</span>是输出的观测值，也称为输出</p><h2 id="无监督学习unsupervised-learning">无监督学习(Unsupervised Learning)</h2><p>无监督学习是指从无标注的数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。无监督学习的本质是学习数据中的统计规律或潜在结构</p><h2 id="强化学习reinforcement-learning">强化学习(Reinforcement Learning)</h2><p>强化学习是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题</p><h1 id="统计学习方法三要素">统计学习方法三要素</h1><h2 id="模型">模型</h2><p>统计学习首要考虑的问题是学习什么样的模型。在监督学习过程中，模型就是<em>所要学习的条件概率分布或决策函数</em>。模型的<strong>假设空间</strong>包含所有可能的条件概率分布或决策函数。</p><p>假设空间用<span class="math inline">\(\mathcal{F}\)</span>表示，假设空间可以定义为决策函数的集合： <span class="math display">\[\mathcal{F} = \left\{f|Y=f(X) \right\}\]</span> 或者条件概率的集合 <span class="math display">\[\mathcal{F} = \left\{P|P(Y|X)\right\}\]</span></p><h2 id="策略">策略</h2><h3 id="损失函数和风险函数">损失函数和风险函数</h3><p>监督学习问题是在假设空间<span class="math inline">\(\mathcal{F}\)</span>中选取模型<span class="math inline">\(f\)</span>作为决策函数，对于给定的输入<span class="math inline">\(X\)</span>，由<span class="math inline">\(f(X)\)</span>给出相应的输出<span class="math inline">\(Y\)</span>，这个输出的预测值与真实值可能存在一定的差别，用一个<strong>损失函数(loss function)</strong>或<strong>代价函数(cost function)</strong>来衡量预测的错误程度。将函数记为<span class="math inline">\(L(Y,f(Y))\)</span></p><p>常用的损失函数有下面几种</p><ol type="1"><li><strong>0-1损失函数</strong> (0-1 loss function)</li></ol><p><span class="math display">\[L(Y, f(X)) = \begin{cases}1, \quad Y \neq f(X)\\0,\quad Y = f(X)\end{cases}\]</span></p><ol start="2" type="1"><li><strong>平方损失函数</strong>(quadratic loss function)</li></ol><p><span class="math display">\[L(Y,f(X)) = (Y-f(X))^2\]</span></p><ol start="3" type="1"><li><strong>绝对损失函数</strong>(absolute loss function)</li></ol><p><span class="math display">\[L(Y,f(X)) = \left|Y-f(X)\right|\]</span></p><ol start="4" type="1"><li><strong>对数损失函数</strong>(logarithmic loss function)或<strong>对数似然损失函数</strong>(log-likelihood loss function)</li></ol><p><span class="math display">\[L(Y,P(Y|X))=-\log P(Y|X)\]</span></p><p>损失函数越小，模型就越好。由于模型的输入、输出是随机变量，所以损失函数的期望是 <span class="math display">\[\begin{aligned}R_{\mathrm{exp}}(f) &amp; = E_{P}[L(Y,f(X))]\\&amp; = \int_{\mathcal{X}\times\mathcal{Y}}L(y, f(x))P(y, x)\mathrm{d}x\mathrm{d}y\end{aligned}\]</span> 这是理论上模型<span class="math inline">\(f(X)\)</span>关于联合分布<span class="math inline">\(P(X,Y)\)</span>的平均意义下的损失，称为<strong>风险函数(risc function)</strong>或<strong>期望损失(expected loss)</strong></p><p>给定一个训练数据集 <span class="math display">\[T=\left\{ (x_1, y_1), (x_2, y_2), \ldots, (x_N, y_N) \right\}\]</span> 模型<span class="math inline">\(f(X)\)</span>关于训练数据集的平均损失度称为<strong>经验风险(empirical risk)</strong>或<strong>经验损失(empirical loss)</strong>，记作<span class="math inline">\(R_{\mathrm{emp}}\)</span> <span class="math display">\[R_{\mathrm{emp}}(f) = \frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i))\]</span> 由大数定律，当<span class="math inline">\(N\to\infty\)</span>时，经验风险趋于风险函数</p><h3 id="经验风险最小化与结构风险最小化">经验风险最小化与结构风险最小化</h3><h4 id="经验风险最小化">经验风险最小化</h4><p>在假设空间、损失函数及训练数据集确定的情况下，经验风险函数就可以确定。<strong>经验风险最小化(empirical risk minimization, ERM)</strong>的策略认为，经验风险最小化的模型是最优的模型。因此求最优模型就是求解最优化问题 <span class="math display">\[\min_{f\in\mathcal{F}}\frac{1}{N}\sum_{i=1}^NL(y_i, f(x_i))\]</span> 当样本容量足够大时，经验风险最小化能保证有很好的学习效果。极大似然估计就是经验风险最小化的一种，当模型是条件概率分布，损失函数时对数损失函数时，两者等价。</p><p>但是，当样本容量很小时，会出现<strong>”过拟合“(over-fitting)</strong>现象</p><h4 id="结构风险最小化">结构风险最小化</h4><p><strong>结构风险最小化(structural risk minimization, SRM)</strong>是为了防止过拟合而提出的策略，结构风险最小化等价于<strong>正则化(regularization)</strong>。结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或罚项(penalty term)。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是： <span class="math display">\[R_{\mathrm{emp}}(f) = \frac{1}{N}\sum_{i=1}^N L(y_i,f(x_i)) + \lambda J(f)\]</span> 其中<span class="math inline">\(J(f)\)</span>为模型的复杂度，是定义在假设空间<span class="math inline">\(\mathcal{F}\)</span>上的泛函。模型<span class="math inline">\(f\)</span>越复杂，复杂度<span class="math inline">\(J(f)\)</span>越大，反之，<span class="math inline">\(f\)</span>越简单，复杂度<span class="math inline">\(J(f)\)</span>越小。<span class="math inline">\(\lambda\geqslant0\)</span>是系数，用以权衡经验风险和模型复杂度。</p><p>结构风险最小化策略认为结构风险最小的模型是最佳模型。所以求最优模型，就是求 <span class="math display">\[\min_{f\in\mathcal{F}}\frac{1}{N}\sum_{i=1}^NL(y_i, f(x_i))+\lambda J(f)\]</span></p><h2 id="算法">算法</h2><p>算法是指学习模型的具体计算方法。</p><h1 id="模型评估与模型选择">模型评估与模型选择</h1><h2 id="训练误差与测试误差">训练误差与测试误差</h2><p>假设学习到的模型是<span class="math inline">\(Y=f(X)\)</span>，训练误差是</p>]]></content>
    
    
    <summary type="html">统计学习及监督学习概论</summary>
    
    
    
    <category term="Notes" scheme="https://liang08.gitlab.io/categories/Notes/"/>
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/categories/Notes/Machine-Learning/"/>
    
    <category term="Statistical Learning Method" scheme="https://liang08.gitlab.io/categories/Notes/Machine-Learning/Statistical-Learning-Method/"/>
    
    
    <category term="Machine Learning" scheme="https://liang08.gitlab.io/tags/Machine-Learning/"/>
    
    <category term="Artificial Intellegence" scheme="https://liang08.gitlab.io/tags/Artificial-Intellegence/"/>
    
  </entry>
  
</feed>
